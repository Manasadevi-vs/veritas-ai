version: "3.9"

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: trustlens_api
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - MLFLOW_TRACKING_URI=sqlite:///mlflow.db

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.ui
    container_name: trustlens_ui
    ports:
      - "8501:8501"
    volumes:
      - .:/app
    depends_on:
      - backend

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.16.2
    container_name: trustlens_mlflow
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
      - ./mlflow.db:/mlflow.db
    command: >
      mlflow ui --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlruns --host 0.0.0.0

  ollama:
    image: ollama/ollama:latest
    container_name: trustlens_ollama
    ports:
      - "11434:11434"
    volumes:
      - E:\OllamaModels:/root/.ollama/models  # use your path
    restart: unless-stopped
